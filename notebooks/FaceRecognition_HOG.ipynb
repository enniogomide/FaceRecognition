{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Face recognition**\n",
        "\n",
        "the python library was used for this work:\n",
        "**face_recognition**\n",
        "\n",
        "link: https://face-recognition.readthedocs.io/en/latest/readme.html\n",
        "\n",
        "\n",
        "The work was carried out using the different examples contained in the library.\n",
        "\n",
        "\n",
        "The following document was used to identify the face_recognition library\n",
        "\n",
        "\n",
        "**Link**: https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78\n",
        "\n",
        "\n",
        "##Steps:\n",
        "Create a folder in google drive (root): “**FaceRecognition**”\n",
        "\n",
        "Added two folders:\n",
        "\n",
        "-> **ImagesTrain**\n",
        "\n",
        "-> **ImagesValidation**\n",
        "\n",
        "within each folder, create new folders with the names of the people to be identified.\n",
        "\n",
        "In the imageTrain folder, only one photo per person\n",
        "\n",
        "In the validation folder, add as many photos as you wish to validate the process.\n",
        "\n",
        "The names of each person, in both the validation and training folders, must be the same."
      ],
      "metadata": {
        "id": "lLDavn2JXq0c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g770Jw-aXb9L",
        "outputId": "e79699bf-b0e7-4d27-c3c9-3dabea4af5b1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (8.1.8)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face_recognition) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from face_recognition) (11.1.0)\n",
            "Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566162 sha256=1946c21100096e1f44def5b807cd985e55718285b463081c141daaf2dc663c5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/52/ec/9355da79c29f160b038a20c784db2803c2f9fa2c8a462c176a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ],
      "source": [
        "# Install de library for face recogntinio. It is required GPU to run\n",
        "#\n",
        "!pip3 install face_recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google drive connection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kRJp5Cph_7aF",
        "outputId": "b3e30911-c7c4-4f8d-d7ac-467868bae45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chage to the FacaRecogniton folder created in the clone process.\n",
        "\n",
        "%cd '/content/drive/MyDrive/FaceRecognition'\n",
        "!pwd\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM7J_OAEA2yY",
        "outputId": "e2f065d4-3e94-48b4-e9cf-a02a4147fe80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/FaceRecognition\n",
            "/content/drive/MyDrive/FaceRecognition\n",
            "total 825\n",
            "-rw------- 1 root root 835954 Jan 21 17:41 encoding_faces_with_class.csv\n",
            "drwx------ 2 root root   4096 Jan 20 18:11 ImagesTrain\n",
            "drwx------ 2 root root   4096 Jan 20 18:11 ImagesValidation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "from PIL import Image, ImageDraw\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "lXR6h2vbYoEX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To train, preparing for the encoding process, there must be inside each folder only one foto, with only one face.\n",
        "# for the validation folder, it must have the same name for the training folder.\n",
        "faces_names =[]\n",
        "faces_encoding = []\n",
        "faces_encoding_names_and_classes = []\n",
        "\n",
        "current_folder = os.getcwd()\n",
        "images_folder = current_folder + \"/ImagesTrain\"\n",
        "folders_name = os.listdir(images_folder)\n",
        "\n",
        "for folder in folders_name:\n",
        "  faces_names.append(folder)\n",
        "  file_list = glob.glob(images_folder + \"/\" + folder + \"/*.*\")\n",
        "  for file_name in file_list:\n",
        "    if file_name:\n",
        "      image_loaded = face_recognition.load_image_file(file_name)\n",
        "      face_encoding = face_recognition.face_encodings(image_loaded)[0]\n",
        "      faces_encoding.append(face_encoding)\n"
      ],
      "metadata": {
        "id": "gcTXi9KZGJzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the files are saved to use in the process of facing recognition\n",
        "\n",
        "# Convert list to numpy array\n",
        "np_data = np.array(faces_names)\n",
        "# Specify the file name\n",
        "filename =  current_folder + '/names_of_faces.csv'\n",
        "# Writing to csv file\n",
        "np.savetxt(filename, np_data, delimiter=\",\", fmt='%s')\n",
        "print(f\"Data saved to {filename}\")\n",
        "\n",
        "# encoding parameters for each face\n",
        "# Specify the file name\n",
        "filename = current_folder + \"/faces_encoding_parameters.csv\"\n",
        "# Writing to csv file\n",
        "np.savetxt(filename, faces_encoding, delimiter=\",\", fmt='%s')\n",
        "print(f\"Data saved to {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC19iLR9QbME",
        "outputId": "adb02d5c-1a12-4c03-a6f5-5056f0906ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to /content/drive/MyDrive/FaceRecognition/names_of_faces.csv\n",
            "Data saved to /content/drive/MyDrive/FaceRecognition/faces_encoding_parameters.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to check the ability to identify the face in diferents photos\n",
        "# for the validation folder, for each person, must have, as many photos as possible, but the folder name, must be the same of training. (encoding)\n",
        "images_folder = current_folder + \"/ImagesValidation\"\n",
        "faces_recognized = []\n",
        "faces_recognized_encoding = []\n",
        "faces_not_recognized = []\n",
        "faces_not_identified = []\n",
        "total_images = 0\n",
        "\n",
        "for folder in folders_name:\n",
        "  file_list = glob.glob(images_folder + \"/\" + folder + \"/*.*\")\n",
        "  total_images += len(file_list)\n",
        "  print(f\"fotos de: {folder} ->  Images qty: {len(file_list)}\")\n",
        "  for file_name in file_list:\n",
        "    if file_name:\n",
        "      image_loaded = face_recognition.load_image_file(file_name)\n",
        "      try:\n",
        "        face_encoding = face_recognition.face_encodings(image_loaded)[0]\n",
        "        matches = face_recognition.compare_faces(faces_encoding, face_encoding)\n",
        "        if (True in matches):\n",
        "          faces_recognized.append(file_name)\n",
        "          class_index = matches.index(True)\n",
        "          face_encoding_with_class = np.insert(face_encoding, 128, class_index)\n",
        "          faces_recognized_encoding.append(face_encoding_with_class)\n",
        "        else:\n",
        "          faces_not_recognized.append(file_name)\n",
        "      except IndexError:\n",
        "        faces_not_identified.append(file_name)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3XpLWDRpG8yr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c708b5d-073e-4c98-e1d5-f09fc7ea66d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fotos de: BarackObama ->  Images qty: 82\n",
            "fotos de: DonaldTrump ->  Images qty: 69\n",
            "fotos de: ElonMusk ->  Images qty: 80\n",
            "fotos de: KeanuReeves ->  Images qty: 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# file with the encoding to use in the structured data classification\n",
        "\n",
        "file_to_save = current_folder + \"/encoding_faces_with_class.csv\"\n",
        "np.savetxt(file_to_save, faces_recognized_encoding, delimiter = \",\")"
      ],
      "metadata": {
        "id": "0PWm8Yjc0Rl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result of the enconding and validation process\n",
        "\n",
        "Of the 302 individual photos submitted, 27 were left untreated because it was not possible to identify the faces, which is usually associated with the quality of the photo or the size of the image.\n",
        "\n",
        "Of the 275 submitted, 21 photos were not recognized. The accuracy of the classification was 92.3%. and 82% if we consider the total number of photos, including those that could not be processed.\n",
        "\n",
        "Another point observed is that the code needs to be better structured in order to have a better treatment and thus ensure a better quality of the result.\n",
        "\n",
        "# Acuracy\n",
        "We can say that the accuracy of identification was 92% for the treated photos and 82% considering the total number of photos submitted.\n"
      ],
      "metadata": {
        "id": "DWHtdbvFlL_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total de fotos: {total_images}\")\n",
        "print(f\"Faces reconhecidas: {len(faces_recognized)}\")\n",
        "print(f\"Faces não reconhecidas: {len(faces_not_recognized)}\")\n",
        "print(f\"Faces não identificadas: {len(faces_not_identified)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhx_Iv6FDyJR",
        "outputId": "4b54e20a-dc00-4997-e970-438aed266c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de fotos: 302\n",
            "Faces reconhecidas: 254\n",
            "Faces não reconhecidas: 21\n",
            "Faces não identificadas: 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Face recogntion using the webcam**\n",
        "Use the “FaceRecognition_HOG_webcam.ipynb” notebook to validate the process using the webcam.\n",
        "\n",
        "The “face_recognition.py” library is required for the process used on the webcam.\n",
        "\n",
        "\n",
        "The data generated at this stage will be imported.\n",
        "\n",
        "\n",
        "#**Face recogntion structured data**\n",
        "In the “FaceRecognition_Structured_data_classification.ipynb” notebook, an attempt was made to use the data generated in this stage (encoding faces) to carry out a classification process using neural networks with the other photos that were correctly classified, with the aim of speeding up the validation process when there is a large volume of data.\n",
        "\n",
        "The results were not good, with an accuracy of 50%, indicating that the configuration needs to be worked on better to see if it achieves the same result for the face_recognition process.\n",
        "\n",
        "The data generated at this stage will be imported.\n"
      ],
      "metadata": {
        "id": "bbJ5HC6gZ0Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yCUyOZ1arDO2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}